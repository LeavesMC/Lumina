From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: MrHua269 <wangxyper@163.com>
Date: Thu, 27 Jun 2024 18:25:12 +0800
Subject: [PATCH] Luminol Linear v2 region format support

This patch is Powered by Luminol(https://github.com/LuminolMC/Luminol)
License:
MIT License

Copyright (c) 2024 LuminolMC

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

diff --git a/build.gradle.kts b/build.gradle.kts
index 2c26932456401bebe45780527e3408cc939955a9..a04c71d96c74d724a792e95fa86b876ef4b3883c 100644
--- a/build.gradle.kts
+++ b/build.gradle.kts
@@ -86,6 +86,11 @@ dependencies {
     implementation("me.lucko:spark-api:0.1-20240720.200737-2")
     implementation("me.lucko:spark-paper:1.10.119-SNAPSHOT")
     // Paper end - spark
+    // Abomination start
+    implementation("com.github.luben:zstd-jni:1.5.4-1")
+    implementation("org.lz4:lz4-java:1.8.0")
+    implementation("net.openhft:zero-allocation-hashing:0.16")
+    // Abomination end
 }
 
 paperweight {
diff --git a/src/main/java/abomination/IRegionFile.java b/src/main/java/abomination/IRegionFile.java
new file mode 100644
index 0000000000000000000000000000000000000000..d92f1d549c7e01daa6b5bba7d405e462a9d57e27
--- /dev/null
+++ b/src/main/java/abomination/IRegionFile.java
@@ -0,0 +1,39 @@
+package abomination;
+
+import ca.spottedleaf.moonrise.patches.chunk_system.storage.ChunkSystemRegionFile;
+import net.minecraft.nbt.CompoundTag;
+import net.minecraft.world.level.ChunkPos;
+
+import java.io.DataInputStream;
+import java.io.DataOutputStream;
+import java.io.IOException;
+import java.nio.ByteBuffer;
+import java.nio.file.Path;
+
+public interface IRegionFile extends ChunkSystemRegionFile {
+    Path getPath();
+
+    DataInputStream getChunkDataInputStream(ChunkPos pos) throws IOException;
+
+    boolean doesChunkExist(ChunkPos pos) throws Exception;
+
+    DataOutputStream getChunkDataOutputStream(ChunkPos pos) throws IOException;
+
+    void flush() throws IOException;
+
+    void clear(ChunkPos pos) throws IOException;
+
+    boolean hasChunk(ChunkPos pos);
+
+    void close() throws IOException;
+
+    void write(ChunkPos pos, ByteBuffer buf) throws IOException;
+
+    CompoundTag getOversizedData(int x, int z) throws IOException;
+
+    boolean isOversized(int x, int z);
+
+    boolean recalculateHeader() throws IOException;
+
+    void setOversized(int x, int z, boolean oversized) throws IOException;
+}
diff --git a/src/main/java/abomination/LinearRegionFile.java b/src/main/java/abomination/LinearRegionFile.java
new file mode 100644
index 0000000000000000000000000000000000000000..bb0fcf5f47b5ae3d86e1d0572f951236afdcd017
--- /dev/null
+++ b/src/main/java/abomination/LinearRegionFile.java
@@ -0,0 +1,622 @@
+package abomination;
+
+import ca.spottedleaf.moonrise.patches.chunk_system.io.MoonriseRegionFileIO;
+import com.github.luben.zstd.ZstdInputStream;
+import com.github.luben.zstd.ZstdOutputStream;
+import com.mojang.logging.LogUtils;
+import net.jpountz.lz4.LZ4Compressor;
+import net.jpountz.lz4.LZ4Factory;
+import net.jpountz.lz4.LZ4FastDecompressor;
+import net.openhft.hashing.LongHashFunction;
+import net.minecraft.nbt.CompoundTag;
+import net.minecraft.world.level.chunk.storage.RegionStorageInfo;
+import net.minecraft.world.level.chunk.storage.RegionFileVersion;
+import net.minecraft.world.level.ChunkPos;
+import org.slf4j.Logger;
+
+import javax.annotation.Nullable;
+import java.io.*;
+import java.nio.ByteBuffer;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.StandardCopyOption;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.locks.LockSupport;
+import java.util.concurrent.locks.ReentrantLock;
+
+// LinearRegionFile_implementation_version_0_5byXymb
+// Just gonna use this string to inform other forks about updates ;-)
+public class LinearRegionFile implements IRegionFile{
+    private static final long SUPERBLOCK = 0xc3ff13183cca9d9aL;
+    private static final byte VERSION = 3;
+    private static final int HEADER_SIZE = 27;
+    private static final int FOOTER_SIZE = 8;
+    private static final Logger LOGGER = LogUtils.getLogger();
+
+    private byte[][] bucketBuffers;
+    private final byte[][] buffer = new byte[1024][];
+    private final int[] bufferUncompressedSize = new int[1024];
+
+    private final long[] chunkTimestamps = new long[1024];
+    private final Object markedToSaveLock = new Object();
+
+    private final LZ4Compressor compressor;
+    private final LZ4FastDecompressor decompressor;
+
+    private boolean markedToSave = false;
+    private boolean close = false;
+
+    public final ReentrantLock fileLock = new ReentrantLock(true);
+    public Path regionFile;
+
+    private final int compressionLevel;
+    private int gridSize = 8;
+    private int bucketSize = 4;
+    private final Thread bindThread;
+
+    public Path getRegionFile() {
+        return this.regionFile;
+    }
+
+    public ReentrantLock getFileLock() {
+        return this.fileLock;
+    }
+
+    private int chunkToBucketIdx(int chunkX, int chunkZ) {
+        int bx = chunkX / bucketSize, bz = chunkZ / bucketSize;
+        return bx * gridSize + bz;
+    }
+
+    private void openBucket(int chunkX, int chunkZ) {
+        chunkX = Math.floorMod(chunkX, 32);
+        chunkZ = Math.floorMod(chunkZ, 32);
+        int idx = chunkToBucketIdx(chunkX, chunkZ);
+
+        if (bucketBuffers == null) return;
+        if (bucketBuffers[idx] != null) {
+            try {
+                ByteArrayInputStream bucketByteStream = new ByteArrayInputStream(bucketBuffers[idx]);
+                ZstdInputStream zstdStream = new ZstdInputStream(bucketByteStream);
+                ByteBuffer bucketBuffer = ByteBuffer.wrap(zstdStream.readAllBytes());
+
+                int bx = chunkX / bucketSize, bz = chunkZ / bucketSize;
+
+                for (int cx = 0; cx < 32 / gridSize; cx++) {
+                    for (int cz = 0; cz < 32 / gridSize; cz++) {
+                        int chunkIndex = (bx * (32 / gridSize) + cx) + (bz * (32 / gridSize) + cz) * 32;
+
+                        int chunkSize = bucketBuffer.getInt();
+                        long timestamp = bucketBuffer.getLong();
+                        this.chunkTimestamps[chunkIndex] = timestamp;
+
+                        if (chunkSize > 0) {
+                            byte[] chunkData = new byte[chunkSize - 8];
+                            bucketBuffer.get(chunkData);
+
+                            int maxCompressedLength = this.compressor.maxCompressedLength(chunkData.length);
+                            byte[] compressed = new byte[maxCompressedLength];
+                            int compressedLength = this.compressor.compress(chunkData, 0, chunkData.length, compressed, 0, maxCompressedLength);
+                            byte[] finalCompressed = new byte[compressedLength];
+                            System.arraycopy(compressed, 0, finalCompressed, 0, compressedLength);
+
+                            // TODO: Optimization - return the requested chunk immediately to save on one LZ4 decompression
+                            this.buffer[chunkIndex] = finalCompressed;
+                            this.bufferUncompressedSize[chunkIndex] = chunkData.length;
+                        }
+                    }
+                }
+            } catch (IOException ex) {
+                throw new RuntimeException("Region file corrupted: " + regionFile + " bucket: " + idx);
+                // TODO: Make sure the server crashes instead of corrupting the world
+            }
+            bucketBuffers[idx] = null;
+        }
+    }
+
+    public boolean regionFileOpen = false;
+
+    private synchronized void openRegionFile() {
+        if (regionFileOpen) return;
+        regionFileOpen = true;
+
+        File regionFile = new File(this.regionFile.toString());
+
+        if(!regionFile.canRead()) {
+            this.bindThread.start();
+            return;
+        }
+
+        try {
+            byte[] fileContent = Files.readAllBytes(this.regionFile);
+            ByteBuffer buffer = ByteBuffer.wrap(fileContent);
+
+            long superBlock = buffer.getLong();
+            if (superBlock != SUPERBLOCK)
+                throw new RuntimeException("Invalid superblock: " + superBlock + " file " + this.regionFile);
+
+            byte version = buffer.get();
+            if (version == 1 || version == 2) {
+                parseLinearV1(buffer);
+            } else if (version == 3) {
+                parseLinearV2(buffer);
+            } else {
+                throw new RuntimeException("Invalid version: " + version + " file " + this.regionFile);
+            }
+
+            this.bindThread.start();
+        } catch (IOException e) {
+            throw new RuntimeException("Failed to open region file " + this.regionFile, e);
+        }
+    }
+
+    private void parseLinearV1(ByteBuffer buffer) throws IOException {
+        final int HEADER_SIZE = 32;
+        final int FOOTER_SIZE = 8;
+
+        // Skip newestTimestamp (Long) + Compression level (Byte) + Chunk count (Short): Unused.
+        buffer.position(buffer.position() + 11);
+
+        int dataCount = buffer.getInt();
+        long fileLength = this.regionFile.toFile().length();
+        if (fileLength != HEADER_SIZE + dataCount + FOOTER_SIZE) {
+            throw new IOException("Invalid file length: " + this.regionFile + " " + fileLength + " " + (HEADER_SIZE + dataCount + FOOTER_SIZE));
+        }
+
+        buffer.position(buffer.position() + 8); // Skip data hash (Long): Unused.
+
+        byte[] rawCompressed = new byte[dataCount];
+        buffer.get(rawCompressed);
+
+        ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(rawCompressed);
+        ZstdInputStream zstdInputStream = new ZstdInputStream(byteArrayInputStream);
+        ByteBuffer decompressedBuffer = ByteBuffer.wrap(zstdInputStream.readAllBytes());
+
+        int[] starts = new int[1024];
+        for (int i = 0; i < 1024; i++) {
+            starts[i] = decompressedBuffer.getInt();
+            decompressedBuffer.getInt(); // Skip timestamps (Int): Unused.
+        }
+
+        for (int i = 0; i < 1024; i++) {
+            if (starts[i] > 0) {
+                int size = starts[i];
+                byte[] chunkData = new byte[size];
+                decompressedBuffer.get(chunkData);
+
+                int maxCompressedLength = this.compressor.maxCompressedLength(size);
+                byte[] compressed = new byte[maxCompressedLength];
+                int compressedLength = this.compressor.compress(chunkData, 0, size, compressed, 0, maxCompressedLength);
+                byte[] finalCompressed = new byte[compressedLength];
+                System.arraycopy(compressed, 0, finalCompressed, 0, compressedLength);
+
+                this.buffer[i] = finalCompressed;
+                this.bufferUncompressedSize[i] = size;
+                this.chunkTimestamps[i] = getTimestamp(); // Use current timestamp as we don't have the original
+            }
+        }
+    }
+
+    private void parseLinearV2(ByteBuffer buffer) throws IOException {
+        buffer.getLong(); // Skip newestTimestamp (Long)
+        gridSize = buffer.get();
+        if (gridSize != 1 && gridSize != 2 && gridSize != 4 && gridSize != 8 && gridSize != 16 && gridSize != 32)
+            throw new RuntimeException("Invalid grid size: " + gridSize + " file " + this.regionFile);
+        bucketSize = 32 / gridSize;
+
+        buffer.getInt(); // Skip region_x (Int)
+        buffer.getInt(); // Skip region_z (Int)
+
+        boolean[] chunkExistenceBitmap = deserializeExistenceBitmap(buffer);
+
+        while (true) {
+            byte featureNameLength = buffer.get();
+            if (featureNameLength == 0) break;
+            byte[] featureNameBytes = new byte[featureNameLength];
+            buffer.get(featureNameBytes);
+            String featureName = new String(featureNameBytes);
+            int featureValue = buffer.getInt();
+            // System.out.println("NBT Feature: " + featureName + " = " + featureValue);
+        }
+
+        int[] bucketSizes = new int[gridSize * gridSize];
+        byte[] bucketCompressionLevels = new byte[gridSize * gridSize];
+        long[] bucketHashes = new long[gridSize * gridSize];
+        for (int i = 0; i < gridSize * gridSize; i++) {
+            bucketSizes[i] = buffer.getInt();
+            bucketCompressionLevels[i] = buffer.get();
+            bucketHashes[i] = buffer.getLong();
+        }
+
+        bucketBuffers = new byte[gridSize * gridSize][];
+        for (int i = 0; i < gridSize * gridSize; i++) {
+            if (bucketSizes[i] > 0) {
+                bucketBuffers[i] = new byte[bucketSizes[i]];
+                buffer.get(bucketBuffers[i]);
+                long rawHash = LongHashFunction.xx().hashBytes(bucketBuffers[i]);
+                if (rawHash != bucketHashes[i]) throw new IOException("Region file hash incorrect " + this.regionFile);
+            }
+        }
+
+        long footerSuperBlock = buffer.getLong();
+        if (footerSuperBlock != SUPERBLOCK)
+            throw new IOException("Footer superblock invalid " + this.regionFile);
+    }
+
+    public LinearRegionFile(RegionStorageInfo storageKey, Path directory, Path path, boolean dsync, int compressionLevel) throws IOException {
+        this(storageKey, directory, path, RegionFileVersion.getCompressionFormat(), dsync, compressionLevel);
+    }
+
+    public LinearRegionFile(RegionStorageInfo storageKey, Path path, Path directory, RegionFileVersion compressionFormat, boolean dsync, int compressionLevel) throws IOException {
+        Runnable flushCheck = () -> {
+            while (!close) {
+                synchronized (saveLock) {
+                    if (markedToSave && activeSaveThreads < SAVE_THREAD_MAX_COUNT) {
+                        activeSaveThreads++;
+                        Runnable flushOperation = () -> {
+                            try {
+                                flush();
+                            } catch (IOException ex) {
+                                LOGGER.error("Region file {} flush failed", this.regionFile.toAbsolutePath(), ex);
+                            } finally {
+                                synchronized (saveLock) {
+                                    activeSaveThreads--;
+                                }
+                            }
+                        };
+
+                        Thread saveThread = USE_VIRTUAL_THREAD ?
+                                Thread.ofVirtual().name("Linear IO - " + LinearRegionFile.this.hashCode()).unstarted(flushOperation) :
+                                Thread.ofPlatform().name("Linear IO - " + LinearRegionFile.this.hashCode()).unstarted(flushOperation);
+                        saveThread.setPriority(Thread.NORM_PRIORITY - 3);
+                        saveThread.start();
+                    }
+                }
+                LockSupport.parkNanos(TimeUnit.MILLISECONDS.toNanos(SAVE_DELAY_MS));
+            }
+        };
+        this.bindThread = USE_VIRTUAL_THREAD ? Thread.ofVirtual().unstarted(flushCheck) : Thread.ofPlatform().unstarted(flushCheck);
+        this.bindThread.setName("Linear IO Schedule - " + this.hashCode());
+        this.regionFile = path;
+        this.compressionLevel = compressionLevel;
+
+        this.compressor = LZ4Factory.fastestInstance().fastCompressor();
+        this.decompressor = LZ4Factory.fastestInstance().fastDecompressor();
+    }
+
+    private synchronized void markToSave() {
+        synchronized(markedToSaveLock) {
+            markedToSave = true;
+        }
+    }
+
+    private synchronized boolean isMarkedToSave() {
+        synchronized(markedToSaveLock) {
+            if(markedToSave) {
+                markedToSave = false;
+                return true;
+            }
+            return false;
+        }
+    }
+
+    public static int SAVE_THREAD_MAX_COUNT = 6;
+    public static int SAVE_DELAY_MS = 100;
+    public static boolean USE_VIRTUAL_THREAD = true;
+    private static final Object saveLock = new Object();
+    private static int activeSaveThreads = 0;
+
+    /*public void run() {
+        while (!close) {
+            synchronized (saveLock) {
+                if (markedToSave && activeSaveThreads < SAVE_THREAD_MAX_COUNT) {
+                    activeSaveThreads++;
+                    Thread saveThread = new Thread(() -> {
+                        try {
+                            flush();
+                        } catch (IOException ex) {
+                            LOGGER.error("Region file " + this.regionFile.toAbsolutePath() + " flush failed", ex);
+                        } finally {
+                            synchronized (saveLock) {
+                                activeSaveThreads--;
+                            }
+                        }
+                    }, "RegionFileFlush");
+                    saveThread.setPriority(Thread.NORM_PRIORITY - 3);
+                    saveThread.start();
+                }
+            }
+            LockSupport.parkNanos(TimeUnit.MILLISECONDS.toNanos(SAVE_DELAY_MS));
+        }
+    }*/
+
+    public synchronized boolean doesChunkExist(ChunkPos pos) throws Exception {
+        openRegionFile();
+        throw new Exception("doesChunkExist is a stub");
+    }
+
+    public synchronized void flush() throws IOException {
+        if(!isMarkedToSave()) return;
+
+        openRegionFile();
+
+        long timestamp = getTimestamp();
+
+long writeStart = System.nanoTime();
+        File tempFile = new File(regionFile.toString() + ".tmp");
+        FileOutputStream fileStream = new FileOutputStream(tempFile);
+        DataOutputStream dataStream = new DataOutputStream(fileStream);
+
+        dataStream.writeLong(SUPERBLOCK);
+        dataStream.writeByte(VERSION);
+        dataStream.writeLong(timestamp);
+        dataStream.writeByte(gridSize);
+
+        String fileName = regionFile.getFileName().toString();
+        String[] parts = fileName.split("\\.");
+        int regionX = 0;
+        int regionZ = 0;
+        try {
+            if (parts.length >= 4) {
+                regionX = Integer.parseInt(parts[1]);
+                regionZ = Integer.parseInt(parts[2]);
+            } else {
+                LOGGER.warn("Unexpected file name format: " + fileName);
+            }
+        } catch (NumberFormatException e) {
+            LOGGER.error("Failed to parse region coordinates from file name: " + fileName, e);
+        }
+
+        dataStream.writeInt(regionX);
+        dataStream.writeInt(regionZ);
+
+        boolean[] chunkExistenceBitmap = new boolean[1024];
+        for (int i = 0; i < 1024; i++) {
+            chunkExistenceBitmap[i] = (this.bufferUncompressedSize[i] > 0);
+        }
+        writeSerializedExistenceBitmap(dataStream, chunkExistenceBitmap);
+
+        writeNBTFeatures(dataStream);
+
+        int bucketMisses = 0;
+        byte[][] buckets = new byte[gridSize * gridSize][];
+        for (int bx = 0; bx < gridSize; bx++) {
+            for (int bz = 0; bz < gridSize; bz++) {
+                if (bucketBuffers != null && bucketBuffers[bx * gridSize + bz] != null) {
+                    buckets[bx * gridSize + bz] = bucketBuffers[bx * gridSize + bz];
+                    continue;
+                }
+                bucketMisses++;
+
+                ByteArrayOutputStream bucketStream = new ByteArrayOutputStream();
+                ZstdOutputStream zstdStream = new ZstdOutputStream(bucketStream, this.compressionLevel);
+                DataOutputStream bucketDataStream = new DataOutputStream(zstdStream);
+
+                boolean hasData = false;
+                for (int cx = 0; cx < 32 / gridSize; cx++) {
+                    for (int cz = 0; cz < 32 / gridSize; cz++) {
+                        int chunkIndex = (bx * 32 / gridSize + cx) + (bz * 32 / gridSize + cz) * 32;
+                        if (this.bufferUncompressedSize[chunkIndex] > 0) {
+                            hasData = true;
+                            byte[] chunkData = new byte[this.bufferUncompressedSize[chunkIndex]];
+                            this.decompressor.decompress(this.buffer[chunkIndex], 0, chunkData, 0, this.bufferUncompressedSize[chunkIndex]);
+                            bucketDataStream.writeInt(chunkData.length + 8);
+                            bucketDataStream.writeLong(this.chunkTimestamps[chunkIndex]);
+                            bucketDataStream.write(chunkData);
+                        } else {
+                            bucketDataStream.writeInt(0);
+                            bucketDataStream.writeLong(this.chunkTimestamps[chunkIndex]);
+                        }
+                    }
+                }
+                bucketDataStream.close();
+
+                if (hasData) {
+                    buckets[bx * gridSize + bz] = bucketStream.toByteArray();
+                }
+            }
+        }
+
+        for (int i = 0; i < gridSize * gridSize; i++) {
+            dataStream.writeInt(buckets[i] != null ? buckets[i].length : 0);
+            dataStream.writeByte(this.compressionLevel);
+            long rawHash = 0;
+            if (buckets[i] != null) {
+                rawHash = LongHashFunction.xx().hashBytes(buckets[i]);
+            }
+            dataStream.writeLong(rawHash);
+        }
+
+        for (int i = 0; i < gridSize * gridSize; i++) {
+            if (buckets[i] != null) {
+                dataStream.write(buckets[i]);
+            }
+        }
+
+        dataStream.writeLong(SUPERBLOCK);
+
+        dataStream.flush();
+        fileStream.getFD().sync();
+        fileStream.getChannel().force(true); // Ensure atomicity on Btrfs
+        dataStream.close();
+
+        fileStream.close();
+        Files.move(tempFile.toPath(), this.regionFile, StandardCopyOption.REPLACE_EXISTING);
+//System.out.println("writeStart REGION FILE FLUSH " + (System.nanoTime() - writeStart) + " misses: " + bucketMisses);
+    }
+
+    private void writeNBTFeatures(DataOutputStream dataStream) throws IOException {
+        // writeNBTFeature(dataStream, "example", 1);
+        dataStream.writeByte(0); // End of NBT features
+    }
+
+    private void writeNBTFeature(DataOutputStream dataStream, String featureName, int featureValue) throws IOException {
+        byte[] featureNameBytes = featureName.getBytes();
+        dataStream.writeByte(featureNameBytes.length);
+        dataStream.write(featureNameBytes);
+        dataStream.writeInt(featureValue);
+    }
+
+    public static final int MAX_CHUNK_SIZE = 500 * 1024 * 1024; // Abomination - prevent chunk dupe
+
+    public synchronized void write(ChunkPos pos, ByteBuffer buffer) {
+        openRegionFile();
+        openBucket(pos.x, pos.z);
+        try {
+            byte[] b = toByteArray(new ByteArrayInputStream(buffer.array()));
+            int uncompressedSize = b.length;
+
+            if (uncompressedSize > MAX_CHUNK_SIZE) {
+                LOGGER.error("Chunk dupe attempt " + this.regionFile);
+                clear(pos);
+            } else {
+                int maxCompressedLength = this.compressor.maxCompressedLength(b.length);
+                byte[] compressed = new byte[maxCompressedLength];
+                int compressedLength = this.compressor.compress(b, 0, b.length, compressed, 0, maxCompressedLength);
+                b = new byte[compressedLength];
+                System.arraycopy(compressed, 0, b, 0, compressedLength);
+
+                int index = getChunkIndex(pos.x, pos.z);
+                this.buffer[index] = b;
+                this.chunkTimestamps[index] = getTimestamp();
+                this.bufferUncompressedSize[getChunkIndex(pos.x, pos.z)] = uncompressedSize;
+            }
+        } catch (IOException e) {
+            LOGGER.error("Chunk write IOException " + e + " " + this.regionFile);
+        }
+        markToSave();
+    }
+
+    public DataOutputStream getChunkDataOutputStream(ChunkPos pos) {
+        openRegionFile();
+        openBucket(pos.x, pos.z);
+        return new DataOutputStream(new BufferedOutputStream(new LinearRegionFile.ChunkBuffer(pos)));
+    }
+
+    @Override
+    public MoonriseRegionFileIO.RegionDataController.WriteData moonrise$startWrite(CompoundTag data, ChunkPos pos) throws IOException {
+        final DataOutputStream out = this.getChunkDataOutputStream(pos);
+
+        return new ca.spottedleaf.moonrise.patches.chunk_system.io.MoonriseRegionFileIO.RegionDataController.WriteData(
+                data, ca.spottedleaf.moonrise.patches.chunk_system.io.MoonriseRegionFileIO.RegionDataController.WriteData.WriteResult.WRITE,
+                out, regionFile -> out.close()
+        );
+    }
+
+    private class ChunkBuffer extends ByteArrayOutputStream {
+
+        private final ChunkPos pos;
+
+        public ChunkBuffer(ChunkPos chunkcoordintpair) {
+            super();
+            this.pos = chunkcoordintpair;
+        }
+
+        public void close() throws IOException {
+            ByteBuffer bytebuffer = ByteBuffer.wrap(this.buf, 0, this.count);
+            LinearRegionFile.this.write(this.pos, bytebuffer);
+        }
+    }
+
+    private byte[] toByteArray(InputStream in) throws IOException {
+        ByteArrayOutputStream out = new ByteArrayOutputStream();
+        byte[] tempBuffer = new byte[4096];
+
+        int length;
+        while ((length = in.read(tempBuffer)) >= 0) {
+            out.write(tempBuffer, 0, length);
+        }
+
+        return out.toByteArray();
+    }
+
+    @Nullable
+    public synchronized DataInputStream getChunkDataInputStream(ChunkPos pos) {
+        openRegionFile();
+        openBucket(pos.x, pos.z);
+
+        if(this.bufferUncompressedSize[getChunkIndex(pos.x, pos.z)] != 0) {
+            byte[] content = new byte[bufferUncompressedSize[getChunkIndex(pos.x, pos.z)]];
+            this.decompressor.decompress(this.buffer[getChunkIndex(pos.x, pos.z)], 0, content, 0, bufferUncompressedSize[getChunkIndex(pos.x, pos.z)]);
+            return new DataInputStream(new ByteArrayInputStream(content));
+        }
+        return null;
+    }
+
+    public synchronized void clear(ChunkPos pos) {
+        openRegionFile();
+        openBucket(pos.x, pos.z);
+        int i = getChunkIndex(pos.x, pos.z);
+        this.buffer[i] = null;
+        this.bufferUncompressedSize[i] = 0;
+        this.chunkTimestamps[i] = 0;
+        markToSave();
+    }
+
+    public synchronized boolean hasChunk(ChunkPos pos) {
+        openRegionFile();
+        openBucket(pos.x, pos.z);
+        return this.bufferUncompressedSize[getChunkIndex(pos.x, pos.z)] > 0;
+    }
+
+    public synchronized void close() throws IOException {
+        openRegionFile();
+        close = true;
+        try {
+            flush();
+        } catch(IOException e) {
+            throw new IOException("Region flush IOException " + e + " " + this.regionFile);
+        }
+    }
+
+    private static int getChunkIndex(int x, int z) {
+        return (x & 31) + ((z & 31) << 5);
+    }
+
+    private static int getTimestamp() {
+        return (int) (System.currentTimeMillis() / 1000L);
+    }
+
+    public boolean recalculateHeader() {
+        return false;
+    }
+
+    public void setOversized(int x, int z, boolean something) {}
+
+    public CompoundTag getOversizedData(int x, int z) throws IOException {
+        throw new IOException("getOversizedData is a stub " + this.regionFile);
+    }
+
+    public boolean isOversized(int x, int z) {
+        return false;
+    }
+
+    public Path getPath() {
+        return this.regionFile;
+    }
+
+    private boolean[] deserializeExistenceBitmap(ByteBuffer buffer) {
+        boolean[] result = new boolean[1024];
+        for (int i = 0; i < 128; i++) {
+            byte b = buffer.get();
+            for (int j = 0; j < 8; j++) {
+                result[i * 8 + j] = ((b >> (7 - j)) & 1) == 1;
+            }
+        }
+        return result;
+    }
+
+    private void writeSerializedExistenceBitmap(DataOutputStream out, boolean[] bitmap) throws IOException {
+        for (int i = 0; i < 128; i++) {
+            byte b = 0;
+            for (int j = 0; j < 8; j++) {
+                if (bitmap[i * 8 + j]) {
+                    b |= (1 << (7 - j));
+                }
+            }
+            out.writeByte(b);
+        }
+    }
+}
diff --git a/src/main/java/ca/spottedleaf/moonrise/patches/chunk_system/io/ChunkSystemRegionFileStorage.java b/src/main/java/ca/spottedleaf/moonrise/patches/chunk_system/io/ChunkSystemRegionFileStorage.java
index a814512fcfb85312474ae2c2c21443843bf57831..2e084a5b28cbe4737f48c25e10af589213525362 100644
--- a/src/main/java/ca/spottedleaf/moonrise/patches/chunk_system/io/ChunkSystemRegionFileStorage.java
+++ b/src/main/java/ca/spottedleaf/moonrise/patches/chunk_system/io/ChunkSystemRegionFileStorage.java
@@ -8,9 +8,9 @@ public interface ChunkSystemRegionFileStorage {
 
     public boolean moonrise$doesRegionFileNotExistNoIO(final int chunkX, final int chunkZ);
 
-    public RegionFile moonrise$getRegionFileIfLoaded(final int chunkX, final int chunkZ);
+    public abomination.IRegionFile moonrise$getRegionFileIfLoaded(final int chunkX, final int chunkZ); // Luminol - Configurable region file format
 
-    public RegionFile moonrise$getRegionFileIfExists(final int chunkX, final int chunkZ) throws IOException;
+    public abomination.IRegionFile moonrise$getRegionFileIfExists(final int chunkX, final int chunkZ) throws IOException; // Luminol - Configurable region file format
 
     public MoonriseRegionFileIO.RegionDataController.WriteData moonrise$startWrite(
             final int chunkX, final int chunkZ, final CompoundTag compound
diff --git a/src/main/java/ca/spottedleaf/moonrise/patches/chunk_system/io/MoonriseRegionFileIO.java b/src/main/java/ca/spottedleaf/moonrise/patches/chunk_system/io/MoonriseRegionFileIO.java
index 1acea58838f057ab87efd103cbecb6f5aeaef393..f9b89684208b9fe2c93f0368f7df5a400061f6c7 100644
--- a/src/main/java/ca/spottedleaf/moonrise/patches/chunk_system/io/MoonriseRegionFileIO.java
+++ b/src/main/java/ca/spottedleaf/moonrise/patches/chunk_system/io/MoonriseRegionFileIO.java
@@ -1462,7 +1462,7 @@ public final class MoonriseRegionFileIO {
 
         public static interface IORunnable {
 
-            public void run(final RegionFile regionFile) throws IOException;
+            public void run(final abomination.IRegionFile regionFile) throws IOException;
 
         }
     }
diff --git a/src/main/java/ca/spottedleaf/moonrise/patches/chunk_system/storage/ChunkSystemChunkBuffer.java b/src/main/java/ca/spottedleaf/moonrise/patches/chunk_system/storage/ChunkSystemChunkBuffer.java
index 51c126735ace8fdde89ad97b5cab62f244212db0..c7d4d944eb198ac53a3eeae717a25c7d5815c8c1 100644
--- a/src/main/java/ca/spottedleaf/moonrise/patches/chunk_system/storage/ChunkSystemChunkBuffer.java
+++ b/src/main/java/ca/spottedleaf/moonrise/patches/chunk_system/storage/ChunkSystemChunkBuffer.java
@@ -8,5 +8,5 @@ public interface ChunkSystemChunkBuffer {
 
     public void moonrise$setWriteOnClose(final boolean value);
 
-    public void moonrise$write(final RegionFile regionFile) throws IOException;
+    public void moonrise$write(final abomination.IRegionFile regionFile) throws IOException; // Luminol - Configurable region file format
 }
diff --git a/src/main/java/me/earthme/luminol/utils/EnumRegionFormat.java b/src/main/java/me/earthme/luminol/utils/EnumRegionFormat.java
new file mode 100644
index 0000000000000000000000000000000000000000..5f6087a96b5bfa035922e7a245f35b180d7d23f0
--- /dev/null
+++ b/src/main/java/me/earthme/luminol/utils/EnumRegionFormat.java
@@ -0,0 +1,40 @@
+package me.earthme.luminol.utils;
+
+import abomination.LinearRegionFile;
+import org.leavesmc.lumina.config.LuminaConfig;
+import net.minecraft.world.level.chunk.storage.RegionFile;
+import org.jetbrains.annotations.Nullable;
+
+public enum EnumRegionFormat {
+    MCA("mca", "mca" , (info) -> new RegionFile(info.info(), info.filePath(), info.folder(), info.sync())),
+    LINEAR_V2("linear_v2", "linear" ,(info) -> new LinearRegionFile(info.info(), info.filePath(), info.folder(), info.sync(), LuminaConfig.configModule().misc.regionFormat.linearCompressionLevel));
+
+    private final String name;
+    private final String argument;
+    private final IRegionCreateFunction creator;
+
+    EnumRegionFormat(String name, String argument, IRegionCreateFunction creator) {
+        this.name = name;
+        this.argument = argument;
+        this.creator = creator;
+    }
+
+    @Nullable
+    public static EnumRegionFormat fromString(String string) {
+        for (EnumRegionFormat format : values()) {
+            if (format.name.equalsIgnoreCase(string)) {
+                return format;
+            }
+        }
+
+        return null;
+    }
+
+    public IRegionCreateFunction getCreator() {
+        return this.creator;
+    }
+
+    public String getArgument() {
+        return this.argument;
+    }
+}
diff --git a/src/main/java/me/earthme/luminol/utils/IRegionCreateFunction.java b/src/main/java/me/earthme/luminol/utils/IRegionCreateFunction.java
new file mode 100644
index 0000000000000000000000000000000000000000..fb87ef13803122aa5a2e7f0c578de359140d4f31
--- /dev/null
+++ b/src/main/java/me/earthme/luminol/utils/IRegionCreateFunction.java
@@ -0,0 +1,9 @@
+package me.earthme.luminol.utils;
+
+import abomination.IRegionFile;
+
+import java.io.IOException;
+
+public interface IRegionCreateFunction {
+    IRegionFile create(RegionCreatorInfo info) throws IOException;
+}
diff --git a/src/main/java/me/earthme/luminol/utils/RegionCreatorInfo.java b/src/main/java/me/earthme/luminol/utils/RegionCreatorInfo.java
new file mode 100644
index 0000000000000000000000000000000000000000..5af068489646ed70330d8c6242ec88f536c4c289
--- /dev/null
+++ b/src/main/java/me/earthme/luminol/utils/RegionCreatorInfo.java
@@ -0,0 +1,7 @@
+package me.earthme.luminol.utils;
+
+import net.minecraft.world.level.chunk.storage.RegionStorageInfo;
+
+import java.nio.file.Path;
+
+public record RegionCreatorInfo (RegionStorageInfo info, Path filePath, Path folder, boolean sync) {}
diff --git a/src/main/java/net/minecraft/server/MinecraftServer.java b/src/main/java/net/minecraft/server/MinecraftServer.java
index 1676c4abb3f6f71bb7b25351aa58b4e127786fca..84e13f30a65fc3963703be0746a4ebd15cc990d4 100644
--- a/src/main/java/net/minecraft/server/MinecraftServer.java
+++ b/src/main/java/net/minecraft/server/MinecraftServer.java
@@ -1036,10 +1036,10 @@ public abstract class MinecraftServer extends ReentrantBlockableEventLoop<TickTa
             while (iterator1.hasNext()) {
                 ServerLevel worldserver2 = (ServerLevel) iterator1.next();
 
-                MinecraftServer.LOGGER.info("ThreadedAnvilChunkStorage ({}): All chunks are saved", worldserver2.getChunkSource().chunkMap.getStorageName());
+                MinecraftServer.LOGGER.info("ThreadedChunkStorage ({}): All chunks are saved", worldserver2.getChunkSource().chunkMap.getStorageName()); // Luminol - configurable region format
             }
 
-            MinecraftServer.LOGGER.info("ThreadedAnvilChunkStorage: All dimensions are saved");
+            MinecraftServer.LOGGER.info("ThreadedChunkStorage: All dimensions are saved"); // Luminol - configurable region format
         }
 
         return flag3;
diff --git a/src/main/java/net/minecraft/util/worldupdate/WorldUpgrader.java b/src/main/java/net/minecraft/util/worldupdate/WorldUpgrader.java
index 622d0cbe023774d92d212f242b60b96317720835..9b4b01a741e8779f4ea06b0fd801ce243e179910 100644
--- a/src/main/java/net/minecraft/util/worldupdate/WorldUpgrader.java
+++ b/src/main/java/net/minecraft/util/worldupdate/WorldUpgrader.java
@@ -75,7 +75,7 @@ public class WorldUpgrader implements AutoCloseable {
     volatile int skipped;
     final Reference2FloatMap<ResourceKey<Level>> progressMap = Reference2FloatMaps.synchronize(new Reference2FloatOpenHashMap());
     volatile Component status = Component.translatable("optimizeWorld.stage.counting");
-    static final Pattern REGEX = Pattern.compile("^r\\.(-?[0-9]+)\\.(-?[0-9]+)\\.mca$");
+    static final Pattern REGEX = Pattern.compile("^r\\.(-?[0-9]+)\\.(-?[0-9]+)\\\\"+ net.minecraft.world.level.chunk.storage.RegionFileStorage.getExtensionName() +"$"); // Luminol - Configurable region file format
     final DimensionDataStorage overworldDataStorage;
 
     public WorldUpgrader(LevelStorageSource.LevelStorageAccess session, DataFixer dataFixer, RegistryAccess dynamicRegistryManager, boolean eraseCache, boolean recreateRegionFiles) {
@@ -399,7 +399,7 @@ public class WorldUpgrader implements AutoCloseable {
 
         private static List<WorldUpgrader.FileToUpgrade> getAllChunkPositions(RegionStorageInfo key, Path regionDirectory) {
             File[] afile = regionDirectory.toFile().listFiles((file, s) -> {
-                return s.endsWith(".mca");
+                return s.endsWith(net.minecraft.world.level.chunk.storage.RegionFileStorage.getExtensionName()); // Luminol - Configurable region file format
             });
 
             if (afile == null) {
@@ -419,7 +419,7 @@ public class WorldUpgrader implements AutoCloseable {
                         List<ChunkPos> list1 = Lists.newArrayList();
 
                         try {
-                            RegionFile regionfile = new RegionFile(key, file.toPath(), regionDirectory, true);
+                            abomination.IRegionFile regionfile = net.minecraft.world.level.chunk.storage.RegionFileStorage.createNew(key, file.toPath(), regionDirectory, true);
 
                             try {
                                 for (int i1 = 0; i1 < 32; ++i1) {
@@ -482,7 +482,7 @@ public class WorldUpgrader implements AutoCloseable {
 
         protected abstract boolean tryProcessOnePosition(T storage, ChunkPos chunkPos, ResourceKey<Level> worldKey);
 
-        private void onFileFinished(RegionFile regionFile) {
+        private void onFileFinished(abomination.IRegionFile regionFile) {
             if (WorldUpgrader.this.recreateRegionFiles) {
                 if (this.previousWriteFuture != null) {
                     this.previousWriteFuture.join();
@@ -507,7 +507,7 @@ public class WorldUpgrader implements AutoCloseable {
         }
     }
 
-    static record FileToUpgrade(RegionFile file, List<ChunkPos> chunksToUpgrade) {
+    static record FileToUpgrade(abomination.IRegionFile file, List<ChunkPos> chunksToUpgrade) {
 
     }
 
diff --git a/src/main/java/net/minecraft/world/level/chunk/storage/RegionFile.java b/src/main/java/net/minecraft/world/level/chunk/storage/RegionFile.java
index 16f07007a0f73ec0c6f421c9b082518e87e8cc7b..fc69834e18e0860750d878e1361722fc38b513f8 100644
--- a/src/main/java/net/minecraft/world/level/chunk/storage/RegionFile.java
+++ b/src/main/java/net/minecraft/world/level/chunk/storage/RegionFile.java
@@ -28,7 +28,7 @@ import net.minecraft.nbt.NbtIo; // Paper
 import net.minecraft.world.level.ChunkPos;
 import org.slf4j.Logger;
 
-public class RegionFile implements AutoCloseable, ca.spottedleaf.moonrise.patches.chunk_system.storage.ChunkSystemRegionFile { // Paper - rewrite chunk system
+public class RegionFile implements AutoCloseable, ca.spottedleaf.moonrise.patches.chunk_system.storage.ChunkSystemRegionFile , abomination.IRegionFile{ // Paper - rewrite chunk system // Luminol - Configurable region file format
 
     private static final Logger LOGGER = LogUtils.getLogger();
     private static final int SECTOR_BYTES = 4096;
@@ -129,7 +129,7 @@ public class RegionFile implements AutoCloseable, ca.spottedleaf.moonrise.patche
     }
 
     // note: only call for CHUNK regionfiles
-    boolean recalculateHeader() throws IOException {
+    public boolean recalculateHeader() throws IOException { // Luminol - Configurable region file format // Luminol - Configurable region file format
         if (!this.canRecalcHeader) {
             return false;
         }
@@ -810,7 +810,7 @@ public class RegionFile implements AutoCloseable, ca.spottedleaf.moonrise.patche
         }
     }
 
-    protected synchronized void write(ChunkPos pos, ByteBuffer buf) throws IOException {
+    public synchronized void write(ChunkPos pos, ByteBuffer buf) throws IOException { // Luminol - Configurable region file format
         int i = RegionFile.getOffsetIndex(pos);
         int j = this.offsets.get(i);
         int k = RegionFile.getSectorNumber(j);
@@ -952,10 +952,10 @@ public class RegionFile implements AutoCloseable, ca.spottedleaf.moonrise.patche
     private static int getChunkIndex(int x, int z) {
         return (x & 31) + (z & 31) * 32;
     }
-    synchronized boolean isOversized(int x, int z) {
+    public synchronized boolean isOversized(int x, int z) { // Luminol - Configurable region file format
         return this.oversized[getChunkIndex(x, z)] == 1;
     }
-    synchronized void setOversized(int x, int z, boolean oversized) throws IOException {
+    public synchronized void setOversized(int x, int z, boolean oversized) throws IOException { // Luminol - Configurable region file format
         final int offset = getChunkIndex(x, z);
         boolean previous = this.oversized[offset] == 1;
         this.oversized[offset] = (byte) (oversized ? 1 : 0);
@@ -994,7 +994,7 @@ public class RegionFile implements AutoCloseable, ca.spottedleaf.moonrise.patche
         return this.path.getParent().resolve(this.path.getFileName().toString().replaceAll("\\.mca$", "") + "_oversized_" + x + "_" + z + ".nbt");
     }
 
-    synchronized CompoundTag getOversizedData(int x, int z) throws IOException {
+    public synchronized CompoundTag getOversizedData(int x, int z) throws IOException { // Luminol - Configurable region file format
         Path file = getOversizedFile(x, z);
         try (DataInputStream out = new DataInputStream(new java.io.BufferedInputStream(new InflaterInputStream(Files.newInputStream(file))))) {
             return NbtIo.read((java.io.DataInput) out);
@@ -1021,7 +1021,7 @@ public class RegionFile implements AutoCloseable, ca.spottedleaf.moonrise.patche
         }
 
         @Override
-        public final void moonrise$write(final RegionFile regionFile) throws IOException {
+        public final void moonrise$write(final abomination.IRegionFile regionFile) throws IOException { // Luminol - Configurable region file format
             regionFile.write(this.pos, ByteBuffer.wrap(this.buf, 0, this.count));
         }
         // Paper end - rewrite chunk system
diff --git a/src/main/java/net/minecraft/world/level/chunk/storage/RegionFileStorage.java b/src/main/java/net/minecraft/world/level/chunk/storage/RegionFileStorage.java
index e40665cead218502b44dd49051a53326ed94f061..912e99d71c5221e853a120ec3ab4bdc68002a9db 100644
--- a/src/main/java/net/minecraft/world/level/chunk/storage/RegionFileStorage.java
+++ b/src/main/java/net/minecraft/world/level/chunk/storage/RegionFileStorage.java
@@ -23,7 +23,7 @@ public class RegionFileStorage implements AutoCloseable, ca.spottedleaf.moonrise
 
     public static final String ANVIL_EXTENSION = ".mca";
     private static final int MAX_CACHE_SIZE = 256;
-    public final Long2ObjectLinkedOpenHashMap<RegionFile> regionCache = new Long2ObjectLinkedOpenHashMap();
+    public final Long2ObjectLinkedOpenHashMap<abomination.IRegionFile> regionCache = new Long2ObjectLinkedOpenHashMap(); // Luminol - Configurable region file format
     private final RegionStorageInfo info;
     private final Path folder;
     private final boolean sync;
@@ -33,8 +33,27 @@ public class RegionFileStorage implements AutoCloseable, ca.spottedleaf.moonrise
     private static final int MAX_NON_EXISTING_CACHE = 1024 * 4;
     private final it.unimi.dsi.fastutil.longs.LongLinkedOpenHashSet nonExistingRegionFiles = new it.unimi.dsi.fastutil.longs.LongLinkedOpenHashSet();
     private static String getRegionFileName(final int chunkX, final int chunkZ) {
-        return "r." + (chunkX >> REGION_SHIFT) + "." + (chunkZ >> REGION_SHIFT) + ".mca";
+        return "r." + (chunkX >> REGION_SHIFT) + "." + (chunkZ >> REGION_SHIFT) + getExtensionName(); // Luminol - Configurable region file format
     }
+    // Luminol start - Configurable region file format
+    public static abomination.IRegionFile createNew(RegionStorageInfo info, Path filePath, Path folder, boolean sync) throws IOException{
+        final me.earthme.luminol.utils.EnumRegionFormat regionFormat = org.leavesmc.lumina.config.LuminaConfig.configModule().misc.regionFormat.regionFormat;
+        final String fullFileName = filePath.getFileName().toString();
+        final String[] fullNameSplit = fullFileName.split("\\.");
+        final String extensionName = fullNameSplit[fullNameSplit.length - 1];
+
+        if (!regionFormat.getArgument().equalsIgnoreCase(extensionName)) {
+            net.minecraft.server.MinecraftServer.setFatalException(new RuntimeException("Invalid region file format: " + extensionName + " expected " + regionFormat.getArgument()));
+            throw new IOException("Invalid region file format: " + extensionName + " expected " + regionFormat.getArgument());
+        }
+
+        return regionFormat.getCreator().create(new me.earthme.luminol.utils.RegionCreatorInfo(info, filePath, folder, sync));
+    }
+
+    public static String getExtensionName() {
+        return "." + org.leavesmc.lumina.config.LuminaConfig.configModule().misc.regionFormat.regionFormat.getArgument();
+    }
+    // Luminol end
 
     private boolean doesRegionFilePossiblyExist(final long position) {
         synchronized (this.nonExistingRegionFiles) {
@@ -68,15 +87,15 @@ public class RegionFileStorage implements AutoCloseable, ca.spottedleaf.moonrise
     }
 
     @Override
-    public synchronized final RegionFile moonrise$getRegionFileIfLoaded(final int chunkX, final int chunkZ) {
+    public synchronized final abomination.IRegionFile moonrise$getRegionFileIfLoaded(final int chunkX, final int chunkZ) { // Luminol - Configurable region file format
         return this.regionCache.getAndMoveToFirst(ChunkPos.asLong(chunkX >> REGION_SHIFT, chunkZ >> REGION_SHIFT));
     }
 
     @Override
-    public synchronized final RegionFile moonrise$getRegionFileIfExists(final int chunkX, final int chunkZ) throws IOException {
+    public synchronized final abomination.IRegionFile moonrise$getRegionFileIfExists(final int chunkX, final int chunkZ) throws IOException {  // Luminol - Configurable region file format
         final long key = ChunkPos.asLong(chunkX >> REGION_SHIFT, chunkZ >> REGION_SHIFT);
 
-        RegionFile ret = this.regionCache.getAndMoveToFirst(key);
+        abomination.IRegionFile ret = this.regionCache.getAndMoveToFirst(key);  // Luminol - Configurable region file format
         if (ret != null) {
             return ret;
         }
@@ -100,7 +119,7 @@ public class RegionFileStorage implements AutoCloseable, ca.spottedleaf.moonrise
 
         FileUtil.createDirectoriesSafe(this.folder);
 
-        ret = new RegionFile(this.info, regionPath, this.folder, this.sync);
+        ret = this.createNew(this.info, regionPath, this.folder, this.sync);  // Luminol - Configurable region file format
 
         this.regionCache.putAndMoveToFirst(key, ret);
 
@@ -119,7 +138,7 @@ public class RegionFileStorage implements AutoCloseable, ca.spottedleaf.moonrise
         }
 
         final ChunkPos pos = new ChunkPos(chunkX, chunkZ);
-        final RegionFile regionFile = this.getRegionFile(pos);
+        final abomination.IRegionFile regionFile = this.getRegionFile(pos);  // Luminol - Configurable region file format
 
         // note: not required to keep regionfile loaded after this call, as the write param takes a regionfile as input
         // (and, the regionfile parameter is unused for writing until the write call)
@@ -153,7 +172,7 @@ public class RegionFileStorage implements AutoCloseable, ca.spottedleaf.moonrise
     ) throws IOException {
         final ChunkPos pos = new ChunkPos(chunkX, chunkZ);
         if (writeData.result() == ca.spottedleaf.moonrise.patches.chunk_system.io.MoonriseRegionFileIO.RegionDataController.WriteData.WriteResult.DELETE) {
-            final RegionFile regionFile = this.moonrise$getRegionFileIfExists(chunkX, chunkZ);
+            final abomination.IRegionFile regionFile = this.moonrise$getRegionFileIfExists(chunkX, chunkZ);  // Luminol - Configurable region file format
             if (regionFile != null) {
                 regionFile.clear(pos);
             } // else: didn't exist
@@ -168,7 +187,7 @@ public class RegionFileStorage implements AutoCloseable, ca.spottedleaf.moonrise
     public final ca.spottedleaf.moonrise.patches.chunk_system.io.MoonriseRegionFileIO.RegionDataController.ReadData moonrise$readData(
         final int chunkX, final int chunkZ
     ) throws IOException {
-        final RegionFile regionFile = this.moonrise$getRegionFileIfExists(chunkX, chunkZ);
+        final abomination.IRegionFile regionFile = this.moonrise$getRegionFileIfExists(chunkX, chunkZ);  // Luminol - Configurable region file format
 
         final DataInputStream input = regionFile == null ? null : regionFile.getChunkDataInputStream(new ChunkPos(chunkX, chunkZ));
 
@@ -221,7 +240,7 @@ public class RegionFileStorage implements AutoCloseable, ca.spottedleaf.moonrise
     @Nullable
     public static ChunkPos getRegionFileCoordinates(Path file) {
         String fileName = file.getFileName().toString();
-        if (!fileName.startsWith("r.") || !fileName.endsWith(".mca")) {
+        if (!fileName.startsWith("r.") || !fileName.endsWith(getExtensionName())) { // Luminol - Configurable region file format
             return null;
         }
 
@@ -250,12 +269,12 @@ public class RegionFileStorage implements AutoCloseable, ca.spottedleaf.moonrise
     }
 
     // Paper start - rewrite chunk system
-    public RegionFile getRegionFile(ChunkPos chunkcoordintpair) throws IOException {
+    public abomination.IRegionFile getRegionFile(ChunkPos chunkcoordintpair) throws IOException {  // Luminol - Configurable region file format
         return this.getRegionFile(chunkcoordintpair, false);
     }
     // Paper end - rewrite chunk system
 
-    public RegionFile getRegionFile(ChunkPos chunkcoordintpair, boolean existingOnly) throws IOException { // CraftBukkit // Paper - public
+    public abomination.IRegionFile getRegionFile(ChunkPos chunkcoordintpair, boolean existingOnly) throws IOException { // CraftBukkit // Paper - public  // Luminol - Configurable region file format
         // Paper start - rewrite chunk system
         if (existingOnly) {
             return this.moonrise$getRegionFileIfExists(chunkcoordintpair.x, chunkcoordintpair.z);
@@ -263,7 +282,7 @@ public class RegionFileStorage implements AutoCloseable, ca.spottedleaf.moonrise
         synchronized (this) {
             final long key = ChunkPos.asLong(chunkcoordintpair.x >> REGION_SHIFT, chunkcoordintpair.z >> REGION_SHIFT);
 
-            RegionFile ret = this.regionCache.getAndMoveToFirst(key);
+            abomination.IRegionFile ret = this.regionCache.getAndMoveToFirst(key);  // Luminol - Configurable region file format
             if (ret != null) {
                 return ret;
             }
@@ -278,7 +297,7 @@ public class RegionFileStorage implements AutoCloseable, ca.spottedleaf.moonrise
 
             FileUtil.createDirectoriesSafe(this.folder);
 
-            ret = new RegionFile(this.info, regionPath, this.folder, this.sync);
+            ret = this.createNew(this.info, regionPath, this.folder, this.sync);
 
             this.regionCache.putAndMoveToFirst(key, ret);
 
@@ -292,7 +311,7 @@ public class RegionFileStorage implements AutoCloseable, ca.spottedleaf.moonrise
         org.apache.logging.log4j.LogManager.getLogger().fatal(msg + " (" + file.toString().replaceAll(".+[\\\\/]", "") + " - " + x + "," + z + ") Go clean it up to remove this message. /minecraft:tp " + (x<<4)+" 128 "+(z<<4) + " - DO NOT REPORT THIS TO PAPER - You may ask for help on Discord, but do not file an issue. These error messages can not be removed.");
     }
 
-    private static CompoundTag readOversizedChunk(RegionFile regionfile, ChunkPos chunkCoordinate) throws IOException {
+    private static CompoundTag readOversizedChunk(abomination.IRegionFile regionfile, ChunkPos chunkCoordinate) throws IOException {  // Luminol - Configurable region file format
         synchronized (regionfile) {
             try (DataInputStream datainputstream = regionfile.getChunkDataInputStream(chunkCoordinate)) {
                 CompoundTag oversizedData = regionfile.getOversizedData(chunkCoordinate.x, chunkCoordinate.z);
@@ -327,7 +346,7 @@ public class RegionFileStorage implements AutoCloseable, ca.spottedleaf.moonrise
     @Nullable
     public CompoundTag read(ChunkPos pos) throws IOException {
         // CraftBukkit start - SPIGOT-5680: There's no good reason to preemptively create files on read, save that for writing
-        RegionFile regionfile = this.getRegionFile(pos, true);
+        abomination.IRegionFile regionfile = this.getRegionFile(pos, true);  // Luminol - Configurable region file format
         if (regionfile == null) {
             return null;
         }
@@ -391,7 +410,7 @@ public class RegionFileStorage implements AutoCloseable, ca.spottedleaf.moonrise
 
     public void scanChunk(ChunkPos chunkPos, StreamTagVisitor scanner) throws IOException {
         // CraftBukkit start - SPIGOT-5680: There's no good reason to preemptively create files on read, save that for writing
-        RegionFile regionfile = this.getRegionFile(chunkPos, true);
+        abomination.IRegionFile regionfile = this.getRegionFile(chunkPos, true);  // Luminol - Configurable region file format
         if (regionfile == null) {
             return;
         }
@@ -421,7 +440,7 @@ public class RegionFileStorage implements AutoCloseable, ca.spottedleaf.moonrise
     }
 
     public void write(ChunkPos pos, @Nullable CompoundTag nbt) throws IOException { // Paper - rewrite chunk system - public
-        RegionFile regionfile = this.getRegionFile(pos, nbt == null); // CraftBukkit // Paper - rewrite chunk system
+        abomination.IRegionFile regionfile = this.getRegionFile(pos, nbt == null); // CraftBukkit // Paper - rewrite chunk system  // Luminol - Configurable region file format
         // Paper start - rewrite chunk system
         if (regionfile == null) {
             // if the RegionFile doesn't exist, no point in deleting from it
@@ -465,7 +484,7 @@ public class RegionFileStorage implements AutoCloseable, ca.spottedleaf.moonrise
         // Paper start - rewrite chunk system
         synchronized (this) {
             final ExceptionCollector<IOException> exceptionCollector = new ExceptionCollector<>();
-            for (final RegionFile regionFile : this.regionCache.values()) {
+            for (final abomination.IRegionFile regionFile : this.regionCache.values()) {  // Luminol - Configurable region file format
                 try {
                     regionFile.close();
                 } catch (final IOException ex) {
@@ -482,7 +501,7 @@ public class RegionFileStorage implements AutoCloseable, ca.spottedleaf.moonrise
         // Paper start - rewrite chunk system
         synchronized (this) {
             final ExceptionCollector<IOException> exceptionCollector = new ExceptionCollector<>();
-            for (final RegionFile regionFile : this.regionCache.values()) {
+            for (final abomination.IRegionFile regionFile : this.regionCache.values()) {  // Luminol - Configurable region file format
                 try {
                     regionFile.flush();
                 } catch (final IOException ex) {
diff --git a/src/main/java/org/leavesmc/lumina/config/modules/misc/RegionFormatConfig.java b/src/main/java/org/leavesmc/lumina/config/modules/misc/RegionFormatConfig.java
index a77ee98609c33e47a36ceb28628bd3ffd49f7614..51338fae13814eadcc83d480abe1b17a9d65817c 100644
--- a/src/main/java/org/leavesmc/lumina/config/modules/misc/RegionFormatConfig.java
+++ b/src/main/java/org/leavesmc/lumina/config/modules/misc/RegionFormatConfig.java
@@ -8,7 +8,7 @@ import org.spongepowered.configurate.objectmapping.meta.PostProcess;
 
 @ConfigSerializable
 public class RegionFormatConfig {
-    public EnumRegionFormat regionFormat;
+    public EnumRegionFormat regionFormat = EnumRegionFormat.MCA;
     public int linearCompressionLevel = 1;
     public int linearIoThreadCount = 6;
     public int linearIoFlushDelayMs = 100;
