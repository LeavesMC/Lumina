From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: MrHua269 <wangxyper@163.com>
Date: Thu, 27 Jun 2024 18:25:12 +0800
Subject: [PATCH] Luminol Linear region format

This patch is Powered by Luminol(https://github.com/LuminolMC/Luminol)
License:
MIT License

Copyright (c) 2024 LuminolMC

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

diff --git a/src/main/java/org/stupidcraft/linearpaper/region/AbstractRegionFile.java b/src/main/java/org/stupidcraft/linearpaper/region/AbstractRegionFile.java
new file mode 100644
index 0000000000000000000000000000000000000000..1325ac1d603bc65224860170b5ffad3f8cca2e9c
--- /dev/null
+++ b/src/main/java/org/stupidcraft/linearpaper/region/AbstractRegionFile.java
@@ -0,0 +1,30 @@
+package org.stupidcraft.linearpaper.region;
+
+import java.io.DataInputStream;
+import java.io.DataOutputStream;
+import java.io.IOException;
+import java.nio.file.Path;
+import java.util.concurrent.locks.ReentrantLock;
+import net.minecraft.nbt.CompoundTag;
+import net.minecraft.world.level.ChunkPos;
+import net.minecraft.world.level.chunk.status.ChunkStatus;
+
+public interface AbstractRegionFile {
+    void flush() throws IOException;
+    void clear(ChunkPos pos) throws IOException;
+    void close() throws IOException;
+    void setStatus(int x, int z, ChunkStatus status);
+    void setOversized(int x, int z, boolean b) throws IOException;
+
+    boolean hasChunk(ChunkPos pos);
+    boolean doesChunkExist(ChunkPos pos) throws Exception;
+    boolean isOversized(int x, int z);
+    boolean recalculateHeader() throws IOException;
+
+    DataOutputStream getChunkDataOutputStream(ChunkPos pos) throws IOException;
+    DataInputStream getChunkDataInputStream(ChunkPos pos) throws IOException;
+    CompoundTag getOversizedData(int x, int z) throws IOException;
+    ChunkStatus getStatusIfCached(int x, int z);
+    ReentrantLock getFileLock();
+    Path getRegionFile();
+}
diff --git a/src/main/java/org/stupidcraft/linearpaper/region/AbstractRegionFileFactory.java b/src/main/java/org/stupidcraft/linearpaper/region/AbstractRegionFileFactory.java
new file mode 100644
index 0000000000000000000000000000000000000000..ddc8391108cff4fd90b046087d519409c00f8bf8
--- /dev/null
+++ b/src/main/java/org/stupidcraft/linearpaper/region/AbstractRegionFileFactory.java
@@ -0,0 +1,40 @@
+package org.stupidcraft.linearpaper.region;
+
+import java.io.IOException;
+import java.nio.file.Path;
+import java.util.Objects;
+
+import net.minecraft.world.level.chunk.storage.RegionFile;
+import net.minecraft.world.level.chunk.storage.RegionFileVersion;
+import net.minecraft.world.level.chunk.storage.RegionStorageInfo;
+import org.jetbrains.annotations.Contract;
+import org.jetbrains.annotations.NotNull;
+import org.leavesmc.lumina.config.LuminaConfig;
+
+public class AbstractRegionFileFactory {
+    @Contract("_, _, _, _ -> new")
+    public static @NotNull AbstractRegionFile getAbstractRegionFile(RegionStorageInfo storageKey, Path directory, Path path, boolean dsync) throws IOException {
+        return getAbstractRegionFile(storageKey, directory, path, RegionFileVersion.getCompressionFormat(), dsync);
+    }
+
+    @Contract("_, _, _, _, _ -> new")
+    public static @NotNull AbstractRegionFile getAbstractRegionFile(RegionStorageInfo storageKey, Path directory, Path path, boolean dsync, boolean canRecalcHeader) throws IOException {
+        return getAbstractRegionFile(storageKey, directory, path, RegionFileVersion.getCompressionFormat(), dsync, canRecalcHeader);
+    }
+
+    @Contract("_, _, _, _, _ -> new")
+    public static @NotNull AbstractRegionFile getAbstractRegionFile(RegionStorageInfo storageKey, Path path, Path directory, RegionFileVersion compressionFormat, boolean dsync) throws IOException {
+        return getAbstractRegionFile(storageKey, path, directory, compressionFormat, dsync, true);
+    }
+
+    @Contract("_, _, _, _, _, _ -> new")
+    public static @NotNull AbstractRegionFile getAbstractRegionFile(RegionStorageInfo storageKey, @NotNull Path path, Path directory, RegionFileVersion compressionFormat, boolean dsync, boolean canRecalcHeader) throws IOException {
+        final String fullFileName = path.getFileName().toString();
+        final String[] fullNameSplit = fullFileName.split("\\.");
+        final String extensionName = fullNameSplit[fullNameSplit.length - 1];
+        if (Objects.requireNonNull(EnumRegionFileExtension.fromExtension(extensionName)) == EnumRegionFileExtension.LINEAR) {
+            return new LinearRegionFile(path, LuminaConfig.configModule().misc.regionFormat.linearCompressionLevel);
+        }
+        return new RegionFile(storageKey, path, directory, compressionFormat, dsync, canRecalcHeader);
+    }
+}
diff --git a/src/main/java/org/stupidcraft/linearpaper/region/EnumRegionFileExtension.java b/src/main/java/org/stupidcraft/linearpaper/region/EnumRegionFileExtension.java
new file mode 100644
index 0000000000000000000000000000000000000000..d51ec3faeb6a78992d440a7996739f4a5f0a5387
--- /dev/null
+++ b/src/main/java/org/stupidcraft/linearpaper/region/EnumRegionFileExtension.java
@@ -0,0 +1,55 @@
+package org.stupidcraft.linearpaper.region;
+
+
+import org.jetbrains.annotations.Contract;
+import org.jetbrains.annotations.NotNull;
+
+public enum EnumRegionFileExtension {
+    LINEAR(".linear"),
+    MCA(".mca"),
+    UNKNOWN(null);
+
+    private final String extensionName;
+
+    EnumRegionFileExtension(String extensionName) {
+        this.extensionName = extensionName;
+    }
+
+    public String getExtensionName() {
+        return this.extensionName;
+    }
+
+    @Contract(pure = true)
+    public static EnumRegionFileExtension fromName(@NotNull String name){
+        switch (name){
+            default -> {
+                return UNKNOWN;
+            }
+
+            case "MCA" -> {
+                return MCA;
+            }
+
+            case "LINEAR" -> {
+                return LINEAR;
+            }
+        }
+    }
+
+    @Contract(pure = true)
+    public static EnumRegionFileExtension fromExtension(@NotNull String name){
+        switch (name){
+            default -> {
+                return UNKNOWN;
+            }
+
+            case ".mca" -> {
+                return MCA;
+            }
+
+            case ".linear" -> {
+                return LINEAR;
+            }
+        }
+    }
+}
diff --git a/src/main/java/org/stupidcraft/linearpaper/region/LinearRegionFile.java b/src/main/java/org/stupidcraft/linearpaper/region/LinearRegionFile.java
new file mode 100644
index 0000000000000000000000000000000000000000..db954f52f8dd39119669742b2c5dd23af846e920
--- /dev/null
+++ b/src/main/java/org/stupidcraft/linearpaper/region/LinearRegionFile.java
@@ -0,0 +1,317 @@
+package org.stupidcraft.linearpaper.region;
+
+import com.github.luben.zstd.ZstdInputStream;
+import com.github.luben.zstd.ZstdOutputStream;
+import com.mojang.logging.LogUtils;
+import java.io.BufferedOutputStream;
+import java.io.ByteArrayInputStream;
+import java.io.ByteArrayOutputStream;
+import java.io.DataInputStream;
+import java.io.DataOutputStream;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.nio.ByteBuffer;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.StandardCopyOption;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicBoolean;
+import java.util.concurrent.locks.ReentrantLock;
+import javax.annotation.Nullable;
+
+import org.leavesmc.lumina.config.LuminaConfig;
+import org.leavesmc.lumina.config.modules.misc.RegionFormatConfig;
+import net.jpountz.lz4.LZ4Compressor;
+import net.jpountz.lz4.LZ4Factory;
+import net.jpountz.lz4.LZ4FastDecompressor;
+import net.minecraft.nbt.CompoundTag;
+import net.minecraft.world.level.ChunkPos;
+import net.minecraft.world.level.chunk.status.ChunkStatus;
+import org.slf4j.Logger;
+
+public class LinearRegionFile implements AbstractRegionFile, AutoCloseable {
+    private static final long SUPERBLOCK = -4323716122432332390L;
+    private static final byte VERSION = 2;
+    private static final int HEADER_SIZE = 32;
+    private static final int FOOTER_SIZE = 8;
+    private static final Logger LOGGER = LogUtils.getLogger();
+    private static final List<Byte> SUPPORTED_VERSIONS = Arrays.asList((byte) 1, (byte) 2);
+    public final ReentrantLock fileLock = new ReentrantLock(true);
+    private final byte[][] buffer = new byte[1024][];
+    private final int[] bufferUncompressedSize = new int[1024];
+    private final int[] chunkTimestamps = new int[1024];
+    private final ChunkStatus[] statuses = new ChunkStatus[1024];
+    private final LZ4Compressor compressor;
+    private final LZ4FastDecompressor decompressor;
+    private final int compressionLevel;
+    public boolean closed = false;
+    public Path path;
+    private volatile long lastFlushed = System.nanoTime();
+
+
+    public LinearRegionFile(Path file, int compression) throws IOException {
+        this.path = file;
+        this.compressionLevel = compression;
+        this.compressor = LZ4Factory.fastestInstance().fastCompressor();
+        this.decompressor = LZ4Factory.fastestInstance().fastDecompressor();
+
+        File regionFile = new File(this.path.toString());
+
+        Arrays.fill(this.bufferUncompressedSize, 0);
+
+        if (!regionFile.canRead()) return;
+
+        try (FileInputStream fileStream = new FileInputStream(regionFile);
+             DataInputStream rawDataStream = new DataInputStream(fileStream)) {
+
+            long superBlock = rawDataStream.readLong();
+            if (superBlock != SUPERBLOCK)
+                throw new RuntimeException("Invalid superblock: " + superBlock + " in " + file);
+
+            byte version = rawDataStream.readByte();
+            if (!SUPPORTED_VERSIONS.contains(version))
+                throw new RuntimeException("Invalid version: " + version + " in " + file);
+
+            // Skip newestTimestamp (Long) + Compression level (Byte) + Chunk count (Short): Unused.
+            rawDataStream.skipBytes(11);
+
+            int dataCount = rawDataStream.readInt();
+            long fileLength = file.toFile().length();
+            if (fileLength != HEADER_SIZE + dataCount + FOOTER_SIZE)
+                throw new IOException("Invalid file length: " + this.path + " " + fileLength + " " + (HEADER_SIZE + dataCount + FOOTER_SIZE));
+
+            rawDataStream.skipBytes(8); // Skip data hash (Long): Unused.
+
+            byte[] rawCompressed = new byte[dataCount];
+            rawDataStream.readFully(rawCompressed, 0, dataCount);
+
+            superBlock = rawDataStream.readLong();
+            if (superBlock != SUPERBLOCK)
+                throw new IOException("Footer superblock invalid " + this.path);
+
+            try (DataInputStream dataStream = new DataInputStream(new ZstdInputStream(new ByteArrayInputStream(rawCompressed)))) {
+
+                int[] starts = new int[1024];
+                for (int i = 0; i < 1024; i++) {
+                    starts[i] = dataStream.readInt();
+                    dataStream.skipBytes(4); // Skip timestamps (Int): Unused.
+                }
+
+                for (int i = 0; i < 1024; i++) {
+                    if (starts[i] > 0) {
+                        int size = starts[i];
+                        byte[] b = new byte[size];
+                        dataStream.readFully(b, 0, size);
+
+                        int maxCompressedLength = this.compressor.maxCompressedLength(size);
+                        byte[] compressed = new byte[maxCompressedLength];
+                        int compressedLength = this.compressor.compress(b, 0, size, compressed, 0, maxCompressedLength);
+                        b = new byte[compressedLength];
+                        System.arraycopy(compressed, 0, b, 0, compressedLength);
+
+                        this.buffer[i] = b;
+                        this.bufferUncompressedSize[i] = size;
+                    }
+                }
+            }
+        }
+    }
+
+    private static int getChunkIndex(int x, int z) {
+        return (x & 31) + ((z & 31) << 5);
+    }
+
+    private static int getTimestamp() {
+        return (int) (System.currentTimeMillis() / 1000L);
+    }
+
+    public Path getRegionFile() {
+        return this.path;
+    }
+
+    public ReentrantLock getFileLock() {
+        return this.fileLock;
+    }
+
+    public void flush() throws IOException {
+        flushWrapper(); // sync
+    }
+
+    public void flushWrapper() {
+        try {
+            save();
+        } catch (IOException e) {
+            LOGGER.error("Failed to flush region file " + path.toAbsolutePath(), e);
+        }
+    }
+
+    public boolean doesChunkExist(ChunkPos pos) throws Exception {
+        throw new Exception("doesChunkExist is a stub");
+    }
+
+    private synchronized void save() throws IOException {
+        long timestamp = getTimestamp();
+        short chunkCount = 0;
+
+        File tempFile = new File(path.toString() + ".tmp");
+
+        try (FileOutputStream fileStream = new FileOutputStream(tempFile);
+             ByteArrayOutputStream zstdByteArray = new ByteArrayOutputStream();
+             ZstdOutputStream zstdStream = new ZstdOutputStream(zstdByteArray, this.compressionLevel);
+             DataOutputStream zstdDataStream = new DataOutputStream(zstdStream);
+             DataOutputStream dataStream = new DataOutputStream(fileStream)) {
+
+            dataStream.writeLong(SUPERBLOCK);
+            dataStream.writeByte(VERSION);
+            dataStream.writeLong(timestamp);
+            dataStream.writeByte(this.compressionLevel);
+
+            ArrayList<byte[]> byteBuffers = new ArrayList<>();
+            for (int i = 0; i < 1024; i++) {
+                if (this.bufferUncompressedSize[i] != 0) {
+                    chunkCount += 1;
+                    byte[] content = new byte[bufferUncompressedSize[i]];
+                    this.decompressor.decompress(buffer[i], 0, content, 0, bufferUncompressedSize[i]);
+
+                    byteBuffers.add(content);
+                } else byteBuffers.add(null);
+            }
+            for (int i = 0; i < 1024; i++) {
+                zstdDataStream.writeInt(this.bufferUncompressedSize[i]); // Write uncompressed size
+                zstdDataStream.writeInt(this.chunkTimestamps[i]); // Write timestamp
+            }
+            for (int i = 0; i < 1024; i++) {
+                if (byteBuffers.get(i) != null)
+                    zstdDataStream.write(byteBuffers.get(i), 0, byteBuffers.get(i).length);
+            }
+            zstdDataStream.close();
+
+            dataStream.writeShort(chunkCount);
+
+            byte[] compressed = zstdByteArray.toByteArray();
+
+            dataStream.writeInt(compressed.length);
+            dataStream.writeLong(0);
+
+            dataStream.write(compressed, 0, compressed.length);
+            dataStream.writeLong(SUPERBLOCK);
+
+            dataStream.flush();
+            fileStream.getFD().sync();
+            fileStream.getChannel().force(true); // Ensure atomicity on Btrfs
+        }
+        Files.move(tempFile.toPath(), this.path, StandardCopyOption.REPLACE_EXISTING);
+        this.lastFlushed = System.nanoTime();
+    }
+
+    public void setStatus(int x, int z, ChunkStatus status) {
+        this.statuses[getChunkIndex(x, z)] = status;
+    }
+
+    public synchronized void write(ChunkPos pos, ByteBuffer buffer) {
+        try {
+            byte[] b = toByteArray(new ByteArrayInputStream(buffer.array()));
+            int uncompressedSize = b.length;
+
+            int maxCompressedLength = this.compressor.maxCompressedLength(b.length);
+            byte[] compressed = new byte[maxCompressedLength];
+            int compressedLength = this.compressor.compress(b, 0, b.length, compressed, 0, maxCompressedLength);
+            b = new byte[compressedLength];
+            System.arraycopy(compressed, 0, b, 0, compressedLength);
+
+            int index = getChunkIndex(pos.x, pos.z);
+            this.buffer[index] = b;
+            this.chunkTimestamps[index] = getTimestamp();
+            this.bufferUncompressedSize[getChunkIndex(pos.x, pos.z)] = uncompressedSize;
+        } catch (IOException e) {
+            LOGGER.error("Chunk write IOException " + e + " " + this.path);
+        }
+
+        if ((System.nanoTime() - this.lastFlushed) >= TimeUnit.NANOSECONDS.toSeconds(LuminaConfig.configModule().misc.regionFormat.linearFlushFrequency)){
+            this.flushWrapper();
+        }
+    }
+
+    public DataOutputStream getChunkDataOutputStream(ChunkPos pos) {
+        return new DataOutputStream(new BufferedOutputStream(new ChunkBuffer(pos)));
+    }
+
+    private byte[] toByteArray(InputStream in) throws IOException {
+        ByteArrayOutputStream out = new ByteArrayOutputStream();
+        byte[] tempBuffer = new byte[4096];
+
+        int length;
+        while ((length = in.read(tempBuffer)) >= 0) {
+            out.write(tempBuffer, 0, length);
+        }
+
+        return out.toByteArray();
+    }
+
+    @Nullable
+    public synchronized DataInputStream getChunkDataInputStream(ChunkPos pos) {
+        if (this.bufferUncompressedSize[getChunkIndex(pos.x, pos.z)] != 0) {
+            byte[] content = new byte[bufferUncompressedSize[getChunkIndex(pos.x, pos.z)]];
+            this.decompressor.decompress(this.buffer[getChunkIndex(pos.x, pos.z)], 0, content, 0, bufferUncompressedSize[getChunkIndex(pos.x, pos.z)]);
+            return new DataInputStream(new ByteArrayInputStream(content));
+        }
+        return null;
+    }
+
+    public ChunkStatus getStatusIfCached(int x, int z) {
+        return this.statuses[getChunkIndex(x, z)];
+    }
+
+    public void clear(ChunkPos pos) {
+        int i = getChunkIndex(pos.x, pos.z);
+        this.buffer[i] = null;
+        this.bufferUncompressedSize[i] = 0;
+        this.chunkTimestamps[i] = getTimestamp();
+        this.flushWrapper();
+    }
+
+    public boolean hasChunk(ChunkPos pos) {
+        return this.bufferUncompressedSize[getChunkIndex(pos.x, pos.z)] > 0;
+    }
+
+    public void close() throws IOException {
+        if (closed) return;
+        closed = true;
+        flush(); // sync
+    }
+
+    public boolean recalculateHeader() {
+        return false;
+    }
+
+    public void setOversized(int x, int z, boolean something) {
+    }
+
+    public CompoundTag getOversizedData(int x, int z) throws IOException {
+        throw new IOException("getOversizedData is a stub " + this.path);
+    }
+
+    public boolean isOversized(int x, int z) {
+        return false;
+    }
+
+    private class ChunkBuffer extends ByteArrayOutputStream {
+        private final ChunkPos pos;
+
+        public ChunkBuffer(ChunkPos chunkcoordintpair) {
+            super();
+            this.pos = chunkcoordintpair;
+        }
+
+        public void close() throws IOException {
+            ByteBuffer bytebuffer = ByteBuffer.wrap(this.buf, 0, this.count);
+            LinearRegionFile.this.write(this.pos, bytebuffer);
+        }
+    }
+}
